{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.3 64-bit",
   "display_name": "Python 3.8.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "0de36b31320ba4c88b4f85a74724f3d16c36a44df48581253710b1065e752d9e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Training a Nerual Network to generate Trump Nicknames\n",
    "\n",
    "This is going to be a word-based approach to nickname generation. We will be going through the preprocessing required to tokenize the nicknames, based off the data set pulled from [this link here]. The data was cleaned and analyzed by me, click [this link here] to see that analysis.\n",
    "\n",
    "# Grabbing the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       fake name           real name  len fake  len real  \\\n",
       "0          dumbo  randolph tex alles         1         3   \n",
       "1  wheres hunter        hunter biden         2         2   \n",
       "2         1% joe           joe biden         2         2   \n",
       "3   basement joe           joe biden         3         2   \n",
       "4    beijing joe           joe biden         3         2   \n",
       "\n",
       "                     category  \\\n",
       "0  domestic political figures   \n",
       "1  domestic political figures   \n",
       "2  domestic political figures   \n",
       "3  domestic political figures   \n",
       "4  domestic political figures   \n",
       "\n",
       "                                               notes  count  \n",
       "0       director of the united states secret service      1  \n",
       "1  american lawyer and lobbyist who is the second...      1  \n",
       "2  47th vice president of the united states; form...      1  \n",
       "3  47th vice president of the united states; form...      1  \n",
       "4  47th vice president of the united states; form...      1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fake name</th>\n      <th>real name</th>\n      <th>len fake</th>\n      <th>len real</th>\n      <th>category</th>\n      <th>notes</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dumbo</td>\n      <td>randolph tex alles</td>\n      <td>1</td>\n      <td>3</td>\n      <td>domestic political figures</td>\n      <td>director of the united states secret service</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>wheres hunter</td>\n      <td>hunter biden</td>\n      <td>2</td>\n      <td>2</td>\n      <td>domestic political figures</td>\n      <td>american lawyer and lobbyist who is the second...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1% joe</td>\n      <td>joe biden</td>\n      <td>2</td>\n      <td>2</td>\n      <td>domestic political figures</td>\n      <td>47th vice president of the united states; form...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>basement joe</td>\n      <td>joe biden</td>\n      <td>3</td>\n      <td>2</td>\n      <td>domestic political figures</td>\n      <td>47th vice president of the united states; form...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>beijing joe</td>\n      <td>joe biden</td>\n      <td>3</td>\n      <td>2</td>\n      <td>domestic political figures</td>\n      <td>47th vice president of the united states; form...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "raw = pd.read_csv('cleaned.nicknames.csv')\n",
    "\n",
    "raw.head()"
   ]
  },
  {
   "source": [
    "Here is the data we are working with. We have the nicknames (fake name) and the corrosponding real name of the individual the nickname was given to by trump. We lso have a few other columns, however those will not matter for this task.\n",
    "\n",
    "# Tokenizing the names\n",
    "\n",
    "Here we need to seperate each word and add a tag. We will be adding a few created tags:\n",
    "\n",
    "+ real names:\n",
    "    - these will be given a tag for each word in the name, for example,\n",
    "        + 'joe biden' will become 'joe <name1> biden <name2>'\n",
    "\n",
    "+ nicknames:\n",
    "    - these follow the rule that if a real name is in the nickname, it will be replaced with the corrosponding real name tag.\n",
    "        + ie, `basement joe` will become `basement <name1>`\n",
    "    - as well as the name substitution, we will add a `<prefix>` tag to every other word before the name, and `<suffix>` to the words after the substitution.\n",
    "\n",
    "These modifications will be made because we will use the generated `<nameX>` tags to use from the user input. For example, if a user inputs `Joe Biden`, and the generated name follows `<prefix> <name1>` the generation algorithm can substitute the users `<name1>` with `joe` in this example, so that all we need to generate is the `<prefix>` tag. If there are no prefix and suffix, then the tag will be `<nope>`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "wheres <name1>\nwheres <prefix> <name1> <suffix>\n1% <name1>\n1% <prefix> <name1> <suffix>\nbasement <name1>\nbasement <prefix> <name1> <suffix>\nbeijing <name1>\nbeijing <prefix> <name1> <suffix>\nchina <name1>\nchina <prefix> <name1> <suffix>\ncorrupt <name1>\ncorrupt <prefix> <name1> <suffix>\ncrazy <name1>\ncrazy <prefix> <name1> <suffix>\nquid pro <name1>\nquid <prefix> pro <prefix> <name1> <suffix>\nsleepy <name1>\nsleepy <prefix> <name1> <suffix>\nsleepy creepy <name1>\nsleepy <prefix> creepy <prefix> <name1> <suffix>\nslow <name1>\nslow <prefix> <name1> <suffix>\n<name1> hiden\n<name1> <suffix> hiden <suffix>\nobiden\nobiden <prefix>\nlittle <name1> <name2>\nlittle <prefix> <name1> <suffix> <name2> <suffix>\nmini mike <name2>\nmini <prefix> mike <prefix> <name2> <suffix>\nda nang <name1>\nda <prefix> nang <prefix> <name1> <suffix>\ngov <name1> moonbeam <name2>\ngov <prefix> <name1> <suffix> moonbeam <suffix> <name2> <suffix>\n<name4> original\n<name4> <suffix> original <suffix>\nlow energy <name1>\nlow <prefix> energy <prefix> <name1> <suffix>\nsleepin <name1> <name2>\nsleepin <prefix> <name1> <suffix> <name2> <suffix>\nwild <name1>\nwild <prefix> <name1> <suffix>\ncrazy <name1>\ncrazy <prefix> <name1> <suffix>\ncrooked <name1>\ncrooked <prefix> <name1> <suffix>\nlyin <name1>\nlyin <prefix> <name1> <suffix>\nheartless <name1>\nheartless <prefix> <name1> <suffix>\nsanctimonious <name1> <name2>\nsanctimonious <prefix> <name1> <suffix> <name2> <suffix>\nleakin <name2>\nleakin <prefix> <name2> <suffix>\nlying <name2>\nlying <prefix> <name2> <suffix>\nshady <name2>\nshady <prefix> <name2> <suffix>\nslippery <name2>\nslippery <prefix> <name2> <suffix>\nslimeball <name2>\nslimeball <prefix> <name2> <suffix>\nliddle <name1> <name2>\nliddle <prefix> <name1> <suffix> <name2> <suffix>\nlyin <name1>\nlyin <prefix> <name1> <suffix>\ntexas <name1>\ntexas <prefix> <name1> <suffix>\nsleepin <name1>\nsleepin <prefix> <name1> <suffix>\ndicky <name2>\ndicky <prefix> <name2> <suffix>\nleaking <name1> <name2>\nleaking <prefix> <name1> <suffix> <name2> <suffix>\nsneaky <name1> <name2>\nsneaky <prefix> <name1> <suffix> <name2> <suffix>\n<name1> flakey\n<name1> <suffix> flakey <suffix>\nrejected senator <name1> <name2>\nrejected <prefix> senator <prefix> <name1> <suffix> <name2> <suffix>\n<name1> frankenstein\n<name1> <suffix> frankenstein <suffix>\nlightweight senator <name1> <name2>\nlightweight <prefix> senator <prefix> <name1> <suffix> <name2> <suffix>\nphony <name1>\nphony <prefix> <name1> <suffix>\npuppet <name2>\npuppet <prefix> <name2> <suffix>\ncorrupt <name2>\ncorrupt <prefix> <name2> <suffix>\n<name2> the sham\n<name2> <suffix> the <suffix> sham <suffix>\n<name1> mcmuffin\n<name1> <suffix> mcmuffin <suffix>\nfat <name1>\nfat <prefix> <name1> <suffix>\nwacky <name1>\nwacky <prefix> <name1> <suffix>\nwacky and deranged <name1>\nwacky <prefix> and <prefix> deranged <prefix> <name1> <suffix>\ncheatin <name2>\ncheatin <prefix> <name2> <suffix>\nfoul mouthed <name2>\nfoul <prefix> mouthed <prefix> <name2> <suffix>\ndummy <name1>\ndummy <prefix> <name1> <suffix>\ntruly weird senator <name1> <name2>\ntruly <prefix> weird <prefix> senator <prefix> <name1> <suffix> <name2> <suffix>\nhigh tax <name1> <name2> \nhigh <prefix> tax <prefix> <name1> <suffix> <name2> <suffix>  <suffix>\nhigh crime <name1> <name2>\nhigh <prefix> crime <prefix> <name1> <suffix> <name2> <suffix>\ncrazy <name1>\ncrazy <prefix> <name1> <suffix>\n<name1>\n<name1> <suffix>\nnervous <name1>\nnervous <prefix> <name1> <suffix>\n<name1> antoinette\n<name1> <suffix> antoinette <suffix>\n<name1> pounce\n<name1> <suffix> pounce <suffix>\nwacky <name1>\nwacky <prefix> <name1> <suffix>\nlittle <name1> \nlittle <prefix> <name1> <suffix>  <suffix>\nliddle <name1>\nliddle <prefix> <name1> <suffix>\n0% <name1> <name2>\n0% <prefix> <name1> <suffix> <name2> <suffix>\nbasically braindead <name1>\nbasically <prefix> braindead <prefix> <name1> <suffix>\ncrazy <name1>\ncrazy <prefix> <name1> <suffix>\nlittle <name1> <name2>\nlittle <prefix> <name1> <suffix> <name2> <suffix>\nshifty <name2>\nshifty <prefix> <name2> <suffix>\n<name1> schitt\n<name1> <suffix> schitt <suffix>\nliddle <name1> <name2>\nliddle <prefix> <name1> <suffix> <name2> <suffix>\ncryin  <name1>\ncryin <prefix>  <prefix> <name1> <suffix>\ncrazy <name1>\ncrazy <prefix> <name1> <suffix>\nimpeachment <name1>\nimpeachment <prefix> <name1> <suffix>\nwacky <name1> <name2>\nwacky <prefix> <name1> <suffix> <name2> <suffix>\nweirdo <name1> <name2>\nweirdo <prefix> <name1> <suffix> <name2> <suffix>\nbig <name1>\nbig <prefix> <name1> <suffix>\ngoofy <name1> <name2>\ngoofy <prefix> <name1> <suffix> <name2> <suffix>\nuber left <name1> <name2>\nuber <prefix> left <prefix> <name1> <suffix> <name2> <suffix>\ncrazy <name1> <name2>\ncrazy <prefix> <name1> <suffix> <name2> <suffix>\nlow iq <name1> <name2>\nlow <prefix> iq <prefix> <name1> <suffix> <name2> <suffix>\n<name1> half <name2>\n<name1> <suffix> half <suffix> <name2> <suffix>\nwacky congresswoman <name2>\nwacky <prefix> congresswoman <prefix> <name2> <suffix>\nanimal <name3>\nanimal <prefix> <name3> <suffix>\nmad <name1>\nmad <prefix> <name1> <suffix>\n<name1> from canada\n<name1> <suffix> from <suffix> canada <suffix>\nsloppy <name1>\nsloppy <prefix> <name1> <suffix>\nwacky <name1> <name2>\nwacky <prefix> <name1> <suffix> <name2> <suffix>\nno talent <name1> <name2>\nno <prefix> talent <prefix> <name1> <suffix> <name2> <suffix>\nlow iq crazy <name1>\nlow <prefix> iq <prefix> crazy <prefix> <name1> <suffix>\nlittle <name1> <name2>\nlittle <prefix> <name1> <suffix> <name2> <suffix>\ncrazy <name1>\ncrazy <prefix> <name1> <suffix>\nsour <name2>\nsour <prefix> <name2> <suffix>\nsloppy <name1> <name2>\nsloppy <prefix> <name1> <suffix> <name2> <suffix>\npsycho <name1>\npsycho <prefix> <name1> <suffix>\nlittle <name1>\nlittle <prefix> <name1> <suffix>\nlittle <name1>\nlittle <prefix> <name1> <suffix>\nmike <name2> wannabe\nmike <prefix> <name2> <suffix> wannabe <suffix>\nlittle <name1> <name2>\nlittle <prefix> <name1> <suffix> <name2> <suffix>\ndopey mort <name2>\ndopey <prefix> mort <prefix> <name2> <suffix>\n<name1> bozo\n<name1> <suffix> bozo <suffix>\n<name1> apple\n<name1> <suffix> apple <suffix>\n<name1> lockheed\n<name1> <suffix> lockheed <suffix>\nmr kellyanne <name2>\nmr <prefix> kellyanne <prefix> <name2> <suffix>\ndopey <name1> <name2>\ndopey <prefix> <name1> <suffix> <name2> <suffix>\nsir <name1>\nsir <prefix> <name1> <suffix>\ngoofball atheist <name1>\ngoofball <prefix> atheist <prefix> <name1> <suffix>\n"
     ]
    }
   ],
   "source": [
    "def tokenize(realname, nickname):\n",
    "\n",
    "    # get a dictionary for the real name and corrospoinding token, ie input\n",
    "    real2token = {word: f'<name{X+1}>' for X, word in enumerate(realname.split(' '))}\n",
    "    # convert dictionary to word tokenized groups and join into single string\n",
    "    real_tokenized = ' '.join([f'{word} {real2token[word]}' for word in real2token])\n",
    "\n",
    "    # change nickname into single string with tokenization and substitution\n",
    "    # grab names to substitute\n",
    "    subs = [sub for sub in realname.split(' ') if sub in nickname]\n",
    "\n",
    "    if len(splits) == 0:\n",
    "        # then there are no splits, tokens are <nope>\n",
    "        nick_tokenized = ' '.join([f'{word} <nope>' for word in nickname.split(' ')])\n",
    "        return nick_tokenized\n",
    "\n",
    "    # \n",
    "    substituted = ' '.join([word if word not in subs else f'{real2token[word]}' for word in nickname.split(' ')])\n",
    "\n",
    "    token = '<prefix>'\n",
    "    tokenized = []\n",
    "\n",
    "    for word in substituted.split(' '):\n",
    "        if '<' in word and 'prefix' in token:\n",
    "            token = '<suffix>'\n",
    "        else:\n",
    "            tokenized.append(f'{word} {token}')\n",
    "    \n",
    "    print(' '.join(tokenized))\n",
    "\n",
    "    # print(f'{nickname}: {substituted}')\n",
    "\n",
    "    # elif 0 < len(nickname.split(' ')) < 3:\n",
    "    #     # then there are splits, however there is only a single prefix of suffix\n",
    "    #     print('-------------')\n",
    "    #     for sub in splits:\n",
    "    #         print(nickname.split(sub))\n",
    "    #     print('-------------')\n",
    "    #     # ' '.join([f'{word} ' for word in nickname.split(' ')])\n",
    "    # elif 3 < len(nickname.split(' ')):\n",
    "    #     print('-------------')\n",
    "    #     for sub in splits:\n",
    "    #         print(nickname.split(sub))\n",
    "    #     print('-------------')\n",
    "        \n",
    "    # nick_tokenized = ' '.join([f'{word} <prefix>' if word not in realname else f'{real2token[word]}' for word in nickname.split(' ')])\n",
    "\n",
    "    # send back tuple of input, output\n",
    "    # return (real_tokenized, nick_tokenized)\n",
    "\n",
    "\n",
    "\n",
    "tokenized_names = [tokenize(realname, nickname) for i, nickname, realname in raw[['fake name', 'real name']].itertuples()]\n",
    "\n",
    "# tokenized_names[0:3]"
   ]
  }
 ]
}